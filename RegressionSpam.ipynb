{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69521330-5009-4d6b-b8d8-31abfbfc6111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.14.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.25.2 in c:\\users\\avern\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy<2,>=1.11.4 in c:\\users\\avern\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.4.2 in c:\\users\\avern\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.7.2)\n",
      "Requirement already satisfied: joblib<2,>=1.2.0 in c:\\users\\avern\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\avern\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n",
      "Downloading imbalanced_learn-0.14.0-py3-none-any.whl (239 kB)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0e21a016-147a-47c5-aebf-b0c1bd50b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5df2291f-6c99-41f4-9237-cd5ac60f1b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ï»¿Message ', 'Verified', 'Category ', 'MessageType'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#we will laod our datasets \n",
    "\n",
    "email_data = pd.read_csv('spam_data/email-spam/email.csv', encoding='latin1')\n",
    "sms_data = pd.read_csv('spam_data/sms-spam/spam.csv', encoding='latin1') \n",
    "combo_data = pd.read_csv('spam_data/hybrid-spam/rcs_sms_spam.csv', encoding='latin1') \n",
    "\n",
    "\n",
    "email_df = pd.DataFrame(email_data)\n",
    "sms_df = pd.DataFrame(sms_data)\n",
    "combo_df = pd.DataFrame(combo_data)\n",
    "\n",
    "combo_df.head(3)\n",
    "print(combo_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "88898118-0b4d-4ea9-a411-0985814407a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to get our data ready for regression we msut make the labels numeric \n",
    "#for both data sets we will change 'ham'->0 and 'spam'-> 1 \n",
    "\n",
    "#do some data cleaning for some issues\n",
    "combo_df.columns = combo_df.columns.str.strip()\n",
    "combo_df = combo_df.rename(columns={'ï»¿Message':'Message'})\n",
    "valid_labels = ['ham', 'spam']\n",
    "combo_df = combo_df[combo_df['Category'].isin(valid_labels)]\n",
    "email_df = email_df[email_df['Category'].isin(valid_labels)]\n",
    "\n",
    "\n",
    "sms_labels = sms_df['v1']\n",
    "sms_data = sms_df['v2'] \n",
    "\n",
    "email_labels = email_df['Category']\n",
    "email_data = email_df['Message'] \n",
    "\n",
    "combo_labels = combo_df['Category'] \n",
    "combo_data = combo_df[['Message', 'Verified','MessageType']]\n",
    "#make the conversion \n",
    "sms_labels = sms_labels.map({'ham': 0, 'spam': 1})\n",
    "email_labels = email_labels.map({'ham': 0, 'spam': 1})\n",
    "combo_labels = combo_labels.map({'ham': 0, 'spam': 1})\n",
    "\n",
    "combo_labels.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35693ed7-0417-4bfe-b053-d4449d8bee55",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#now that are data is cleaned up we can create the train.test splits \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m training_sms_data, testing_sms_data, training_sms_labels, testing_sms_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(sms_data, sms_labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\n\u001b[0;32m      3\u001b[0m training_email_data, testing_email_data, training_email_labels, testing_email_labels \u001b[38;5;241m=\u001b[39m train_test_split(email_data, email_labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\n\u001b[0;32m      4\u001b[0m training_combo_data, testing_combo_data, training_combo_labels, testing_combo_labels \u001b[38;5;241m=\u001b[39m train_test_split(combo_data, combo_labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "#now that are data is cleaned up we can create the train.test splits \n",
    "training_sms_data, testing_sms_data, training_sms_labels, testing_sms_labels = train_test_split(sms_data, sms_labels, test_size=0.3)\n",
    "training_email_data, testing_email_data, training_email_labels, testing_email_labels = train_test_split(email_data, email_labels, test_size=0.3)\n",
    "training_combo_data, testing_combo_data, training_combo_labels, testing_combo_labels = train_test_split(combo_data, combo_labels, test_size=0.3)\n",
    "\n",
    "\n",
    "training_combo_message = training_combo_data['Message']\n",
    "testing_combo_message = testing_combo_data['Message']\n",
    "\n",
    "#vectorize the data again (just messages in case of combo data ) \n",
    "vectorizer1 = TfidfVectorizer(stop_words='english')\n",
    "training_sms_data_vect = vectorizer1.fit_transform(training_sms_data)\n",
    "testing_sms_data_vect = vectorizer1.transform(testing_sms_data)\n",
    "\n",
    "vectorizer2 = TfidfVectorizer(stop_words='english')\n",
    "training_email_data_vect = vectorizer2.fit_transform(training_email_data)\n",
    "testing_email_data_vect = vectorizer2.transform(testing_email_data)\n",
    "\n",
    "vectorizer3 = TfidfVectorizer(stop_words='english')\n",
    "training_combo_message_vect = vectorizer3.fit_transform(training_combo_message)\n",
    "testing_combo_message_vect = vectorizer3.transform(testing_combo_message)\n",
    "\n",
    "train_combo_meta = training_combo_data[['Verified', 'MessageType']].values\n",
    "test_combo_meta = testing_combo_data[['Verified', 'MessageType']].values\n",
    "\n",
    "training_combo_data_vect = hstack([training_combo_message_vect, csr_matrix(train_combo_meta)], format='csr')\n",
    "testing_combo_data_vect = hstack([testing_combo_message_vect, csr_matrix(test_combo_meta)], format='csr')\n",
    "\n",
    "#just to experiement... \n",
    "ros = RandomOverSampler()\n",
    "x_resampled, y_resampled = ros.fit_resample(training_combo_data_vect, training_combo_labels)\n",
    "\n",
    "#now we can train the models \n",
    "\n",
    "lr_sms = LogisticRegression(max_iter = 1000)\n",
    "lr_sms.fit(training_sms_data_vect, training_sms_labels)\n",
    "\n",
    "lr_email = LogisticRegression(max_iter = 1000)\n",
    "lr_email.fit(training_email_data_vect, training_email_labels)\n",
    "\n",
    "lr_combo =  LogisticRegression(max_iter = 1000)\n",
    "#lr_combo.fit(training_combo_data_vect, training_combo_labels)\n",
    "lr_combo.fit(x_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52369dc7-1c2d-4864-a947-64f6c3096419",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr_sms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# and now we can predict and print results \u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m pred_sms \u001b[38;5;241m=\u001b[39m \u001b[43mlr_sms\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(testing_sms_data_vect)\n\u001b[0;32m      4\u001b[0m pred_email \u001b[38;5;241m=\u001b[39m lr_email\u001b[38;5;241m.\u001b[39mpredict(testing_email_data_vect) \n\u001b[0;32m      5\u001b[0m pred_combo \u001b[38;5;241m=\u001b[39m lr_combo\u001b[38;5;241m.\u001b[39mpredict(testing_combo_data_vect) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'lr_sms' is not defined"
     ]
    }
   ],
   "source": [
    "# and now we can predict and print results \n",
    "\n",
    "pred_sms = lr_sms.predict(testing_sms_data_vect)\n",
    "pred_email = lr_email.predict(testing_email_data_vect) \n",
    "pred_combo = lr_combo.predict(testing_combo_data_vect) \n",
    "\n",
    "testing_sms_labels = testing_sms_labels.fillna(0)\n",
    "testing_email_labels = testing_email_labels.fillna(0)\n",
    "testing_combo_labels = testing_combo_labels.fillna(0)\n",
    "\n",
    "\n",
    "print(\"SMS Logistic Regression\")\n",
    "print(\"Precision:\", precision_score(testing_sms_labels, pred_sms))\n",
    "print(\"Recall:\", recall_score(testing_sms_labels, pred_sms))\n",
    "print(\"F1:\", f1_score(testing_sms_labels, pred_sms))\n",
    "print(\"Accuracy:\", accuracy_score(testing_sms_labels, pred_sms))\n",
    "\n",
    "print(\"\\nEmail Logistic Regression\")\n",
    "print(\"Precision:\", precision_score(testing_email_labels, pred_email))\n",
    "print(\"Recall:\", recall_score(testing_email_labels, pred_email))\n",
    "print(\"F1:\", f1_score(testing_email_labels, pred_email))\n",
    "print(\"Accuracy:\", accuracy_score(testing_email_labels, pred_email))\n",
    "\n",
    "print(\"\\nCombo Logistic Regression\")\n",
    "print(\"Precision:\", precision_score(testing_combo_labels, pred_combo))\n",
    "print(\"Recall:\", recall_score(testing_combo_labels, pred_combo))\n",
    "print(\"F1:\", f1_score(testing_combo_labels, pred_combo))\n",
    "print(\"Accuracy:\", accuracy_score(testing_combo_labels, pred_combo))\n",
    "\n",
    "print(\"\\nCombo Logistic Regression + Logic with Custom Data \")\n",
    "hits = misses = 0 \n",
    "for index,row in combo_df.iterrows(): \n",
    "    if row['Category'] == 'spam': \n",
    "        if predict_spam(row) == 1: \n",
    "            hits+=1 \n",
    "            continue \n",
    "        else: \n",
    "            misses += 1 \n",
    "            continue \n",
    "    if row['Category'] == 'ham': \n",
    "        if predict_spam(row) == 0:\n",
    "            hits += 1 \n",
    "            continue \n",
    "        else: \n",
    "            misses+=1\n",
    "            continue\n",
    "\n",
    "print(\"Accuracy: \", hits / (hits + misses))\n",
    "\n",
    "print(\"\\nSMS Logistic Regression with Custom Data \")\n",
    "hits = misses = 0 \n",
    "for index,row in combo_df.iterrows(): \n",
    "    message_vect = vectorizer1.transform([row['Message']])\n",
    "    prediction = lr_sms.predict(message_vect) \n",
    "\n",
    "    if prediction == 1:\n",
    "        if row['Category'] == 'spam':\n",
    "            hits+=1 \n",
    "        else:\n",
    "            misses +=1 \n",
    "    else:\n",
    "        if row['Category'] == 'ham':\n",
    "            hits +=1 \n",
    "        else:\n",
    "            misses += 1\n",
    "\n",
    "print(\"Accuracy: \", hits / (hits + misses))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1a89427c-7c88-45d8-857b-e1c6d49668c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will implement our hybrid model that uses rcs and sms as paramers in addition to the message \n",
    "def predict_spam(data):\n",
    "   # print(\"Message: \", data['Message'])\n",
    "    if data['MessageType'] == 1: #RCS \n",
    "        if data['Verified'] ==1: #verified by Google \n",
    "            #print(\"0\")\n",
    "            return 0 # not spam \n",
    "             #SMS or unverified RCS \n",
    "    msg_vect = vectorizer1.transform([data['Message']])#sti.l need to convert message\n",
    "    #print(\"USING ML\", lr_sms.predict(msg_vect)[0])\n",
    "    return lr_sms.predict(msg_vect)[0]\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f34580-16e7-439b-8609-a3705c1226d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
